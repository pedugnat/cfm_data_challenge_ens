{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "kmeans-smote 0.1.2 requires imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.7.0 which is incompatible.\n",
      "kmeans-smote 0.1.2 requires numpy<1.16,>=1.13, but you'll have numpy 1.18.5 which is incompatible.\n",
      "kmeans-smote 0.1.2 requires scikit-learn<0.21,>=0.19.0, but you'll have scikit-learn 0.23.2 which is incompatible.\n",
      "dask-xgboost 0.1.11 requires xgboost<=0.90, but you'll have xgboost 1.2.1 which is incompatible.\n",
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n",
      "Kernel lancé le : 20 Jan, 18 h 40\n"
     ]
    }
   ],
   "source": [
    "import re, gc, os, json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from preprocessing_script import *\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "\n",
    "NB_VENUES = 6\n",
    "MICROSEC = int(1e6)\n",
    "MIN_PER_HOUR = 60\n",
    "SEC_PER_MIN = 60\n",
    "TARGET = \"source_id\"\n",
    "FEATURES_LIST = list()\n",
    "BASE_DATA_PATH = \"./input/cfmdatachallenge/\"\n",
    "\n",
    "print(f\"Kernel lancé le : {datetime.now().strftime('%d %b, %H h %M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = read_data_files(BASE_DATA_PATH, \"train.h5\", \"test.h5\", \"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_prices(price_columns: list, df: pd.DataFrame, nb_venues: int) -> pd.DataFrame:\n",
    "    if len(price_columns) != nb_venues:\n",
    "        raise ValueError(\n",
    "            f\"Not the right number of columns: {nb_venues} expected, got {len(price_columns)}\")\n",
    "\n",
    "    prices = df[price_columns].values\n",
    "    # ranks the columns : each column is assigned a 0->5 int\n",
    "    ordered_prices = scipy.stats.rankdata(prices, method=\"average\", axis=1)\n",
    "    rank_cols = [f\"{col}_rank\" for col in price_columns]\n",
    "\n",
    "    df_ordered_prices = pd.DataFrame(ordered_prices,\n",
    "                                     columns=rank_cols,\n",
    "                                     index=df.index,\n",
    "                                     dtype=np.float16)\n",
    "\n",
    "    return df_ordered_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining Processing and Features Engineering...\n",
      "\n",
      "Columns renamed\n",
      "Columns renamed\n",
      "Trade times normalized\n",
      "Trade times normalized\n",
      "5 last venues frequency computed\n",
      "5 last venues frequency computed\n",
      "10 last venues frequency computed\n",
      "10 last venues frequency computed\n",
      "Order book normalized\n",
      "Order book normalized\n",
      "Total book size computed\n",
      "Total book size computed\n",
      "Bid prices normalized\n",
      "Bid prices normalized\n",
      "Weighted quantity price feature computed\n",
      "Weighted quantity price feature computed\n",
      "Features on last trades computed\n",
      "Features on last trades computed\n",
      "Prices normalize vs. best done!\n",
      "Prices normalize vs. best done!\n",
      "Ratios created!\n",
      "Ratios created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/usr/lib/preprocessing_script/preprocessing_script.py:495: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  df[norm_cols_names] = df_OB_cols / sum_kbest_prices\n",
      "/kaggle/usr/lib/preprocessing_script/preprocessing_script.py:495: RuntimeWarning: invalid value encountered in true_divide\n",
      "  df[norm_cols_names] = df_OB_cols / sum_kbest_prices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OB features normalised by sum of 3 best\n",
      "OB features normalised by sum of 3 best\n",
      "\n",
      "Features Engineering Completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Begining Processing and Features Engineering...\\n\")\n",
    "\n",
    "# Rename columns to make them more readable\n",
    "\n",
    "train_data = rename_columns(train_data)\n",
    "test_data  = rename_columns(test_data)\n",
    "\n",
    "# Time transformation: from microseconds to quarters/minutes\n",
    "# Only do it for the last trade as feats would be correlated if we did it for the 10 last trades\n",
    "\n",
    "for df in [train_data, test_data]:\n",
    "    df[\"trade_quarter\"] = df[\"trade_tod_0\"].apply(get_quarter_from_time)\n",
    "    df[\"trade_minute\"]  = df[\"trade_tod_0\"].apply(get_minute_from_time)\n",
    "\n",
    "FEATURES_LIST.extend([\"trade_quarter\", \"trade_minute\"])\n",
    "\n",
    "# Normalise time for 10 last trades by time of most recent trade\n",
    "#Convert `trade_tod_i` from absolute time to time relative to last trade to measure the time difference between the trades\n",
    "\n",
    "train_data = normalize_trades_time(train_data)\n",
    "test_data  = normalize_trades_time(test_data)\n",
    "\n",
    "# Frequency of venues among last k trades\n",
    "\n",
    "last_n_trades = [5, 10]\n",
    "\n",
    "for last_k in last_n_trades:\n",
    "    train_data = get_venues_frequency_last_trades(train_data, last_k)\n",
    "    test_data  = get_venues_frequency_last_trades(test_data,  last_k)\n",
    "    \n",
    "# Normalise updates by time to most recent update\n",
    "\n",
    "train_data = normalize_OB_updates(train_data)\n",
    "test_data  = normalize_OB_updates(test_data)\n",
    "\n",
    "# Total book size per venue\n",
    "\n",
    "train_data = compute_total_book_size(train_data)\n",
    "test_data  = compute_total_book_size(test_data)\n",
    "\n",
    "# Opposite transform of bid prices to make it \"same scale\"\n",
    "\n",
    "train_data = normalize_prices(train_data)\n",
    "test_data  = normalize_prices(test_data)\n",
    "\n",
    "# Weighted best OB (qty * 1/price**2)\n",
    "\n",
    "train_data = get_weighted_qty_price(train_data)\n",
    "test_data  = get_weighted_qty_price(test_data)\n",
    "\n",
    "# Rank order books for best to worst price offered\n",
    "\n",
    "train_data = rank_venues_by_price(train_data)\n",
    "test_data  = rank_venues_by_price(test_data)\n",
    "\n",
    "# Features on last trades\n",
    "\n",
    "train_data = make_stats_on_lasttrades(train_data)\n",
    "test_data  = make_stats_on_lasttrades(test_data)\n",
    "\n",
    "# Biggest / bestprice trade feature\n",
    "\n",
    "train_data = biggest_best_trade_feats(train_data)\n",
    "test_data  = biggest_best_trade_feats(test_data)\n",
    "\n",
    "# Making prices relative to the best available price\n",
    "\n",
    "bid_ask_prices = [r\"OB_ask_[0-5]$\", r\"OB_ask1_[0-5]$\", r\"OB_bid_[0-5]$\", r\"OB_bid1_[0-5]$\"]\n",
    "train_data = make_relative_price_features(train_data, bid_ask_prices)\n",
    "test_data  = make_relative_price_features(test_data , bid_ask_prices)\n",
    "\n",
    "# Make ratios between 1st and 2nd level of the book for size and price\n",
    "\n",
    "train_data = make_ratios_price_size(train_data)\n",
    "test_data  = make_ratios_price_size(test_data)\n",
    "\n",
    "# Normalizing the features by the k best of the 6 OBs\n",
    "# slightly worsens the score (by 0.02%)\n",
    "\n",
    "k_best_feats = 3\n",
    "train_data = get_weighted_OB_share(train_data, k_best_feats)\n",
    "test_data  = get_weighted_OB_share(test_data,  k_best_feats)\n",
    "\n",
    "\n",
    "# Trades on n last seconds\n",
    "train_data = trades_last_n_sec(train_data, limit_time=int(1e3))\n",
    "train_data = trades_last_n_sec(train_data, limit_time=int(1e2))\n",
    "train_data = trades_last_n_sec(train_data, limit_time=int(1e1))\n",
    "\n",
    "test_data = trades_last_n_sec(test_data, limit_time=int(1e3))\n",
    "test_data = trades_last_n_sec(test_data, limit_time=int(1e2))\n",
    "test_data = trades_last_n_sec(test_data, limit_time=int(1e1))\n",
    "\n",
    "\n",
    "print(\"\\nFeatures Engineering Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock + quarter categorical variable\n",
    "\n",
    "#train_data[\"stock_quarter\"] = train_data[\"stock_id\"].astype(str) + \"_\" + train_data[\"trade_quarter\"].astype(str)\n",
    "#test_data[\"stock_quarter\"]  = test_data[\"stock_id\"].astype(str)  + \"_\" + test_data[\"trade_quarter\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODE_OB_FEATS = False\n",
    "\n",
    "if ENCODE_OB_FEATS:\n",
    "    patt = \"OB_(bid|ask)1?_[0-5]$\"\n",
    "    agg_names = [\"med\"]\n",
    "    train_data = encode_OB_features(train_data, patt, agg_names)\n",
    "    test_data  = encode_OB_features(test_data,  patt, agg_names)\n",
    "    \n",
    "    FEATURES_LIST.extend([c for c in train_data.columns if \"_encoded\" in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stockday encoding done!\n"
     ]
    }
   ],
   "source": [
    "STOCKDAY_ENCODING = True\n",
    "\n",
    "if STOCKDAY_ENCODING:\n",
    "    stockday_columns = [\"stock_id\", \"day_id\"]\n",
    "    source_cols = [c for c in train_data.columns if \"trade_source_id_\" in c]\n",
    "    \n",
    "    features = dict()\n",
    "    mapping = dict()\n",
    "    train_test_mapping = list()\n",
    "    \n",
    "    for df in [train_data, test_data]:\n",
    "        for k, df_gp in df.groupby(stockday_columns):\n",
    "            \n",
    "            df_gp_source = df_gp[source_cols].values\n",
    "            nb_samples = 10 * df_gp_source.shape[0]\n",
    "            \n",
    "            for i in range(NB_VENUES):\n",
    "                features[i] = np.count_nonzero(df_gp_source == i) / nb_samples\n",
    "\n",
    "            mapping[k] = features\n",
    "            features = dict()\n",
    "\n",
    "        mapping_stock_day = pd.DataFrame(mapping).T\n",
    "        mapping_stock_day.reset_index(inplace=True)\n",
    "        mapping_stock_day.columns = stockday_columns + [f\"venue_stockday_{k}\" for k in range(NB_VENUES)]\n",
    "        \n",
    "        train_test_mapping.append(mapping_stock_day)\n",
    "        \n",
    "    test_data = test_data.reset_index()\n",
    "        \n",
    "    train_data = train_data.merge(train_test_mapping[0], on=stockday_columns)\n",
    "    test_data  = test_data .merge(train_test_mapping[1], on=stockday_columns)\n",
    "    \n",
    "    test_data = test_data.set_index(\"ID\")\n",
    "\n",
    "    FEATURES_LIST.extend([f\"venue_stockday_{k}\" for k in range(NB_VENUES)])\n",
    "    del df; gc.collect()\n",
    "\n",
    "print(\"Stockday encoding done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f \"^.{1-7}$\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OB_ask_1_sum_norm                 985\n",
       "OB_ask_5_sum_norm                1016\n",
       "OB_bid_4_sum_norm                1039\n",
       "OB_bid_5_sum_norm                1093\n",
       "OB_bid_1_sum_norm                1110\n",
       "OB_ts_last_update_2_sum_norm     8120\n",
       "OB_ts_last_update_0_sum_norm    11582\n",
       "ask_size_2                      15357\n",
       "OB_ask_size1_2                  15357\n",
       "OB_ask1_2                       15357\n",
       "normalized_OB_ask1_2            15357\n",
       "OB_ts_last_update_3_sum_norm    16947\n",
       "OB_bid1_2                       18378\n",
       "bid_size_2                      18378\n",
       "OB_bid_size1_2                  18378\n",
       "normalized_OB_bid1_2            18378\n",
       "OB_ts_last_update_4_sum_norm    24444\n",
       "OB_ts_last_update_5_sum_norm    25618\n",
       "total_size_2                    28059\n",
       "OB_ts_last_update_1_sum_norm    28981\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isna().sum().sort_values().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test : try to \"double features by giving the previous line for stock and day as a feature\"\n",
    "\n",
    "def make_lag_feature(df: pd.DataFrame, feats_to_lag: List[str]) -> pd.DataFrame:\n",
    "    sorted_data = df.sort_values(by=[\"stock_id\", \"day_id\"])\n",
    "    lagged_features = sorted_data.shift(1)\n",
    "    lagged_features = lagged_features[[f for f in feats_to_lag if f in lagged_features.columns]]\n",
    "    lagged_features.columns = [\"lagged_\" + c for c in lagged_features.columns]\n",
    "    df = pd.concat([sorted_data, lagged_features], axis=1)\n",
    "\n",
    "    df[\"change_stock_day\"] = (sorted_data[\"stock_id\"] != sorted_data[\"stock_id\"].shift(1)) | (sorted_data[\"day_id\"] != sorted_data[\"day_id\"].shift(1))\n",
    "    lagged_cols = [c for c in df.columns if \"lagged\" in c]\n",
    "    lagged_naned_data = df[lagged_cols].values\n",
    "    lagged_naned_data[df[\"change_stock_day\"], :] = np.nan\n",
    "    \n",
    "    df = df.drop(\"change_stock_day\", axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = make_lag_feature(train_data, best_features)\n",
    "# test_data  = make_lag_feature(test_data, best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups of features used :\n",
      "\n",
      "['OB_ask_', 'OB_ask__sum_norm', 'OB_ask_size_', 'OB_bid_', 'OB_bid__sum_norm', 'OB_bid_size_', 'OB_ts_last_update_', 'OB_ts_last_update__sum_norm', 'ask_size_', 'bid_size_', 'day_id', 'last_trades__.', 'max_lasttrades_price', 'max_lasttrades_qty', 'mean_lasttrades_price', 'mean_lasttrades_qty', 'min_lasttrades_price', 'min_lasttrades_qty', 'nb__past_venues', 'normalized_OB_ask_', 'normalized_OB_bid_', 'num_lasttrades_ask_side', 'ratio__ask?__', 'ratio__ask_size?__', 'ratio__bid?__', 'ratio__bid_size?__', 'source_id', 'std_lasttrades_price', 'std_lasttrades_qty', 'std_lasttrades_time', 'stock_id', 'total_size_', 'trade_minute', 'trade_price_', 'trade_qty_', 'trade_quarter', 'trade_source_id_', 'trade_tod_', 'venue_stockday_', 'weighted_ask_OB_price_', 'weighted_bid_OB_price_']\n"
     ]
    }
   ],
   "source": [
    "print(\"Groups of features used :\\n\")\n",
    "main_features_groups = sorted(set([''.join([l for l in c if not l.isdigit()]) for c in train_data.columns]))\n",
    "print(main_features_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946657, 241)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 946657 entries, 0 to 946656\n",
      "Columns: 241 entries, OB_ask_0 to venue_stockday_5\n",
      "dtypes: float32(118), float64(67), int16(12), int64(31), int8(13)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train data with feature engineering...\n",
      "Saving test data with feature engineering...\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving train data with feature engineering...\")\n",
    "train_data.to_csv(\"train_data.csv\")\n",
    "\n",
    "print(\"Saving test data with feature engineering...\")\n",
    "test_data.to_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
